import { debugLog } from './log.js'

export type LLMProvider = 'anthropic' | 'openai' | 'deepseek' | 'local'

export interface ProviderConfig {
  provider: LLMProvider
  model: string
  skipPermissions?: boolean
}

/**
 * æ ¹æ®æ¨¡åž‹åç§°è‡ªåŠ¨é€‰æ‹© LLM æä¾›å•†
 */
export function getProviderFromModel(model: string): LLMProvider {
  debugLog(`ðŸ” [DEBUG] getProviderFromModel - Input model: ${model}`)
  
  // ä¼˜å…ˆæ£€æŸ¥localæ”¯æŒçš„æ¨¡åž‹
  const localSupportedModels = [
    'DeepSeek-V3-W8A8', 'deepseek-chat', 'gpt-4o', 'gpt-4o-mini', 'gpt-3.5-turbo'
  ]
  
  if (localSupportedModels.includes(model)) {
    debugLog(`âœ… [DEBUG] getProviderFromModel - Model ${model} matched local supported models, returning 'local'`)
    return 'local'
  }
  
  // æ£€æŸ¥OpenAIæ¨¡åž‹æ¨¡å¼
  if (model.startsWith('gpt-')) {
    debugLog(`âœ… [DEBUG] getProviderFromModel - Model ${model} matched OpenAI pattern, returning 'openai'`)
    return 'openai'
  }
  
  // æ£€æŸ¥localæ¨¡åž‹æ¨¡å¼
  if (model.startsWith('local-')) {
    debugLog(`âœ… [DEBUG] getProviderFromModel - Model ${model} matched local pattern, returning 'local'`)
    return 'local'
  }
  
  // æ£€æŸ¥DeepSeekæ¨¡åž‹æ¨¡å¼
  if (model.startsWith('deepseek-') || model.includes('deepseek')) {
    debugLog(`âœ… [DEBUG] getProviderFromModel - Model ${model} matched DeepSeek pattern, returning 'deepseek'`)
    return 'deepseek'
  }
  
  // é»˜è®¤è¿”å›žanthropic
  debugLog(`âœ… [DEBUG] getProviderFromModel - Model ${model} defaulting to 'anthropic'`)
  return 'anthropic'
}

/**
 * æ£€æŸ¥æ˜¯å¦éœ€è¦è·³è¿‡æƒé™éªŒè¯
 * éž Anthropic æä¾›å•†é»˜è®¤è·³è¿‡æƒé™éªŒè¯
 */
export function shouldSkipPermissions(provider: LLMProvider): boolean {
  return provider === 'openai' || provider === 'deepseek' || provider === 'local'
}

/**
 * èŽ·å–æä¾›å•†é…ç½®
 */
export function getProviderConfig(model: string): ProviderConfig {
  const provider = getProviderFromModel(model)
  return {
    provider,
    model,
    skipPermissions: shouldSkipPermissions(provider),
  }
}

/**
 * éªŒè¯æ¨¡åž‹æ˜¯å¦æ”¯æŒ
 */
export function isModelSupported(model: string): boolean {
  const provider = getProviderFromModel(model)
  
  if (provider === 'openai') {
    // OpenAI æ”¯æŒçš„æ¨¡åž‹
    const openaiModels = [
      'gpt-4', 'gpt-4-turbo', 'gpt-4o', 'gpt-4o-mini',
      'gpt-3.5-turbo', 'gpt-3.5-turbo-16k'
    ]
    return openaiModels.some(supported => model.includes(supported))
  }
  
  if (provider === 'deepseek') {
    // DeepSeek æ”¯æŒçš„æ¨¡åž‹
    const deepseekModels = [
      'deepseek-chat', 'deepseek-coder', 'deepseek-reasoner',
      'deepseek-v2.5', 'deepseek-v2.5-chat', 'deepseek-v2.5-coder',
    ]
    return deepseekModels.some(supported => model.includes(supported))
  }
  
  if (provider === 'local') {
    // Local provider æ”¯æŒçš„æ¨¡åž‹
    const localModels = [
      'DeepSeek-V3-W8A8', 'deepseek-chat', 'gpt-4o', 'gpt-4o-mini'
    ]
    return localModels.some(supported => model.includes(supported)) || true // ä¹Ÿæ”¯æŒå…¶ä»–ä»»ä½•æ¨¡åž‹
  }

  if (provider === 'anthropic') {
    // Anthropic æ”¯æŒçš„æ¨¡åž‹
    const anthropicModels = [
      'claude-3-5-sonnet', 'claude-3-5-haiku', 'claude-3-opus',
      'claude-3-sonnet', 'claude-3-haiku', 'claude-2'
    ]
    return anthropicModels.some(supported => model.includes(supported))
  }
  
  return false
} 