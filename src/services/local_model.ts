import crypto from 'crypto'
import type { AssistantMessage, UserMessage } from '../query.js'
import type { Tool } from '../Tool.js'
import { debugLog, logError } from '../utils/log.js'
import jwt from 'jsonwebtoken'

// è®¾ç½®SSLéªŒè¯è·³è¿‡ï¼Œå¿…é¡»åœ¨ä»»ä½•HTTPSè¯·æ±‚ä¹‹å‰è®¾ç½®
process.env.NODE_TLS_REJECT_UNAUTHORIZED = '0'

/**
 * ç¯å¢ƒå˜é‡
 * LOCAL_MODEL_BASE é»˜è®¤ https://192.168.10.173/sdw/chatbot/sysai/v1
 * LOCAL_MODEL_API_KEY å¯é€‰
 */
const LOCAL_MODEL_BASE = process.env.LOCAL_MODEL_BASE || 'https://192.168.10.173/sdw/chatbot/sysai/v1'
const LOCAL_MODEL_API_KEY = process.env.LOCAL_MODEL_API_KEY || ''

// ç”ŸæˆJWT tokençš„å‡½æ•°
function generateJWTToken(): string {
  const payload = {
    appId: "agent",
    userId: "exampleUser",
    username: "Example Nickname",
    exp: Math.floor(Date.now() / 1000) + (3 * 24 * 60 * 60) // 3å¤©åè¿‡æœŸ
  }
  const secretKey = '!@#DFwerw453n'
  return jwt.sign(payload, secretKey, { algorithm: 'HS256' })
}

interface LocalMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
}

interface LocalTool {
  type: 'function'
  function: {
    name: string
    description: string
    parameters: Record<string, unknown>
  }
}

interface LocalRequest {
  model: string
  messages: LocalMessage[]
  max_tokens?: number
  stream?: boolean
  temperature?: number
  top_p?: number
  presence_penalty?: number
  frequency_penalty?: number
  tools?: LocalTool[]
}

interface LocalStreamDelta {
  role?: string
  content?: string
  finish_reason?: string | null
  tool_calls?: Array<{
    index: number
    id?: string
    function: {
      name: string
      arguments: string
    }
  }>
}

interface LocalStreamChoice {
  index: number
  delta: LocalStreamDelta
  finish_reason: string | null
}

interface LocalStreamResponse {
  id: string
  object: string
  created: number
  model: string
  choices: LocalStreamChoice[]
  usage?: {
    prompt_tokens: number
    completion_tokens: number
    total_tokens: number
  }
}

interface LocalResponse {
  id: string
  object: string
  created: number
  model: string
  choices: Array<{
    index: number
    message: {
      content?: string
      tool_calls?: Array<{
        function: { name: string; arguments: string }
      }>
    }
    finish_reason: string | null
  }>
  usage?: {
    prompt_tokens: number
    completion_tokens: number
    total_tokens: number
  }
  error?: {
    message: string
    code: string
  }
}

/**
 * å°† UserMessage è½¬æ¢ä¸º LocalMessage - å‚è€ƒ localAdapter.ts
 */
function userMessageToLocal(message: UserMessage): LocalMessage {
  if (typeof message.message.content === 'string') {
    return { role: 'user', content: message.message.content }
  }

  // å¤„ç† content æ•°ç»„ - å‚è€ƒ localAdapter.ts çš„ convertToDeepseekMessages
  const segments: string[] = []
  for (const part of message.message.content) {
    if (part.type === 'text') {
      segments.push(part.text)
    } else if ('functionCall' in part) {
      segments.push('[FunctionCall] ' + JSON.stringify(part.functionCall))
    } else if ('functionResponse' in part) {
      segments.push('[FunctionResponse] ' + JSON.stringify(part.functionResponse))
    }
  }
  
  const text = segments.join('\n')
  return { role: 'user', content: text }
}

/**
 * å°† AssistantMessage è½¬æ¢ä¸º LocalMessage - å‚è€ƒ localAdapter.ts
 */
function assistantMessageToLocal(message: AssistantMessage): LocalMessage {
  if (message.message.content.length === 0) {
    return { role: 'assistant', content: '' }
  }
  
  // å¤„ç† content æ•°ç»„ - å‚è€ƒ localAdapter.ts
  const segments: string[] = []
  for (const part of message.message.content) {
    if (part.type === 'text') {
      segments.push(part.text)
    } else if ('functionCall' in part) {
      segments.push('[FunctionCall] ' + JSON.stringify(part.functionCall))
    } else if ('functionResponse' in part) {
      segments.push('[FunctionResponse] ' + JSON.stringify(part.functionResponse))
    }
  }
  
  const text = segments.join('\n')
  return { role: 'assistant', content: text }
}

function toolsToLocal(tools: Tool[]): LocalTool[] {
  if (!tools || !Array.isArray(tools)) {
    return [];
  }

  return tools.map(tool => {
    // è·å–å·¥å…·çš„schema - å·¥å…·å¯èƒ½ä½¿ç”¨inputSchemaè€Œä¸æ˜¯schema
    let schema = (tool as any).schema;
    if (!schema && (tool as any).inputSchema) {
      schema = (tool as any).inputSchema;
    }
    
    // å¤„ç† Claude Code æ ¼å¼çš„ Tool - å‚è€ƒ localAdapter.ts
    const normalizedTool = {
      type: 'function' as const,
      function: {
        name: tool.name,
        description: tool.description || '',
        parameters: normalizeParameters(schema || {})
      }
    };
    
    debugLog(`ğŸ”§ [DEBUG] toolsToLocal - Converting tool: ${tool.name}`)
    debugLog(`ğŸ”§ [DEBUG] toolsToLocal - Tool schema:`, JSON.stringify(schema || {}, null, 2))
    
    return normalizedTool;
  });
}

/**
 * æ ‡å‡†åŒ–å‚æ•°æ ¼å¼ - å‚è€ƒ localAdapter.ts çš„ normalizeParameters
 */
function normalizeParameters(parameters: unknown): Record<string, unknown> {
  if (!parameters) {
    return {};
  }

  // å¦‚æœæ˜¯Zod schemaå¯¹è±¡ï¼Œå°è¯•æå–å…¶ç»“æ„
  if (typeof parameters === 'object' && parameters !== null) {
    const zodObj = parameters as any;
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯Zodå¯¹è±¡
    if (zodObj._def && zodObj._def.typeName === 'ZodObject') {
      debugLog(`ğŸ”§ [DEBUG] normalizeParameters - Detected Zod schema, converting to JSON Schema`)
      
      // ä¸ºZod schemaåˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„JSON Schemaç»“æ„
      return {
        type: 'object',
        properties: {},
        required: [],
        additionalProperties: false
      };
    }
  }

  const normalizeType = (type: string): string => {
    const typeMap: Record<string, string> = {
      'STRING': 'string',
      'NUMBER': 'number',
      'BOOLEAN': 'boolean',
      'OBJECT': 'object',
      'ARRAY': 'array',
      'INTEGER': 'integer'
    };
    return typeMap[type] || type;
  };

  const normalizeSchema = (schema: unknown): Record<string, unknown> => {
    if (typeof schema !== 'object' || schema === null) {
      return {};
    }

    const normalized = { ...schema as Record<string, unknown> };

    if ('type' in normalized && typeof normalized.type === 'string') {
      normalized.type = normalizeType(normalized.type as string);
    }

    if ('items' in normalized) {
      normalized.items = normalizeSchema(normalized.items);
    }

    if ('properties' in normalized && normalized.properties && typeof normalized.properties === 'object') {
      const normalizedProperties: Record<string, unknown> = {};
      for (const [key, value] of Object.entries(normalized.properties as Record<string, unknown>)) {
        normalizedProperties[key] = normalizeSchema(value);
      }
      normalized.properties = normalizedProperties;
    }

    return normalized;
  };

  return normalizeSchema(parameters);
}

/**
 * æ ¹æ®æ¨¡å‹åç§°æ£€æµ‹æ¨¡å‹ç±»å‹ - å‚è€ƒ localAdapter.ts
 */
function detectModelType(modelName: string): string {
  const lowerModel = modelName.toLowerCase();
  
  // DeepSeek æ¨¡å‹æ£€æµ‹
  if (lowerModel.includes('deepseek') || lowerModel.includes('coder')) {
    return 'deepseek-coder';
  }
  
  // OpenAI å…¼å®¹æ¨¡å‹æ£€æµ‹
  if (lowerModel.includes('gpt') || lowerModel.includes('openai')) {
    return 'gpt';
  }
  
  // Claude æ¨¡å‹æ£€æµ‹
  if (lowerModel.includes('claude')) {
    return 'claude';
  }
  
  // Llama æ¨¡å‹æ£€æµ‹
  if (lowerModel.includes('llama') || lowerModel.includes('llm')) {
    return 'llama';
  }
  
  // Qwen æ¨¡å‹æ£€æµ‹
  if (lowerModel.includes('qwen')) {
    return 'qwen';
  }
  
  // ChatGLM æ¨¡å‹æ£€æµ‹
  if (lowerModel.includes('chatglm') || lowerModel.includes('glm')) {
    return 'chatglm';
  }
  
  // é€šç”¨æ¨¡å‹æ£€æµ‹
  if (lowerModel.includes('chat') || lowerModel.includes('assistant')) {
    return 'chat';
  }
  
  // é»˜è®¤è¿”å›æ¨¡å‹åç§°
  return modelName;
}

/**
 * æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´è¯·æ±‚å‚æ•° - å‚è€ƒ localAdapter.ts
 */
function adjustRequestForModel(requestObj: any, modelType: string): void {
  debugLog(`ğŸ”§ [DEBUG] adjustRequestForModel - Model type: ${modelType}`)
  
  switch (modelType) {
    case 'deepseek-coder':
      // DeepSeek ç‰¹å®šé…ç½®
      requestObj.temperature = requestObj.temperature ?? 0.7;
      requestObj.top_p = requestObj.top_p ?? 0.95;
      break;
      
    case 'gpt':
      // OpenAI å…¼å®¹é…ç½®
      requestObj.temperature = requestObj.temperature ?? 0.7;
      requestObj.top_p = requestObj.top_p ?? 1;
      break;
      
    case 'claude':
      // Claude é…ç½®
      requestObj.temperature = requestObj.temperature ?? 0.7;
      requestObj.top_p = requestObj.top_p ?? 0.9;
      break;
      
    case 'llama':
      // Llama é…ç½®
      requestObj.temperature = requestObj.temperature ?? 0.8;
      requestObj.top_p = requestObj.top_p ?? 0.9;
      break;
      
    case 'qwen':
      // Qwen é…ç½®
      requestObj.temperature = requestObj.temperature ?? 0.7;
      requestObj.top_p = requestObj.top_p ?? 0.9;
      break;
      
    case 'chatglm':
      // ChatGLM é…ç½®
      requestObj.temperature = requestObj.temperature ?? 0.7;
      requestObj.top_p = requestObj.top_p ?? 0.9;
      break;
      
    default:
      // é€šç”¨é…ç½®
      requestObj.temperature = requestObj.temperature ?? 0.7;
      requestObj.top_p = requestObj.top_p ?? 0.9;
      break;
  }
  
  debugLog(`ğŸ”§ [DEBUG] adjustRequestForModel - Adjusted temperature: ${requestObj.temperature}`)
  debugLog(`ğŸ”§ [DEBUG] adjustRequestForModel - Adjusted top_p: ${requestObj.top_p}`)
}

/**
 * æ„é€  HTTP è¯·æ±‚å¹¶è§£æå“åº”
 */
async function callLocalModel(request: LocalRequest, signal: AbortSignal): Promise<LocalResponse> {
  const url = LOCAL_MODEL_BASE.replace(/\/+$/, '') + '/chat/completions'
  const headers: Record<string, string> = { 'Content-Type': 'application/json' }
  
  // ä½¿ç”¨JWT tokenè¿›è¡Œè®¤è¯
  const jwtToken = generateJWTToken()
  headers['Authorization'] = `Bearer ${jwtToken}`

  debugLog(`ğŸ” [DEBUG] callLocalModel - URL: ${url}`)
  debugLog(`ğŸ” [DEBUG] callLocalModel - Headers:`, JSON.stringify(headers, null, 2))
  debugLog(`ğŸ” [DEBUG] callLocalModel - Request body:`, JSON.stringify(request, null, 2))
  debugLog(`ğŸ” [DEBUG] callLocalModel - LOCAL_MODEL_BASE: ${LOCAL_MODEL_BASE}`)
  debugLog(`ğŸ” [DEBUG] callLocalModel - JWT Token generated: ${jwtToken.substring(0, 20)}...`)

  // æ·»åŠ è¯¦ç»†çš„è¯·æ±‚æ•°æ®æ‰“å°
  debugLog(`\nğŸ“‹ [DEBUG] callLocalModel - ===== å®Œæ•´è¯·æ±‚æ•°æ® =====`)
  debugLog(`ğŸ“‹ [DEBUG] callLocalModel - è¯·æ±‚URL: ${url}`)
  debugLog(`ğŸ“‹ [DEBUG] callLocalModel - è¯·æ±‚æ–¹æ³•: POST`)
  debugLog(`ğŸ“‹ [DEBUG] callLocalModel - è¯·æ±‚Headers:`)
  Object.entries(headers).forEach(([key, value]) => {
    debugLog(`ğŸ“‹ [DEBUG] callLocalModel -   ${key}: ${key === 'Authorization' ? value.substring(0, 50) + '...' : value}`)
  })
  debugLog(`ğŸ“‹ [DEBUG] callLocalModel - è¯·æ±‚ä½“å¤§å°: ${JSON.stringify(request).length} å­—ç¬¦`)
  debugLog(`ğŸ“‹ [DEBUG] callLocalModel - è¯·æ±‚ä½“å†…å®¹:`)
  debugLog(JSON.stringify(request, null, 2))
  debugLog(`ğŸ“‹ [DEBUG] callLocalModel - ===== è¯·æ±‚æ•°æ®ç»“æŸ =====\n`)

  try {
    debugLog(`ğŸŒ [DEBUG] callLocalModel - Making fetch request to: ${url}`)
    
    // è®¾ç½®è¶…æ—¶ - å‚è€ƒlocalAdapter.tsçš„å®ç°
    const timeout = parseInt(process.env.LOCAL_MODEL_TIMEOUT || '30000') // é»˜è®¤30ç§’
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), timeout)
    
    // åˆå¹¶signal
    const combinedSignal = new AbortController()
    signal.addEventListener('abort', () => combinedSignal.abort())
    controller.signal.addEventListener('abort', () => combinedSignal.abort())
    
    const fetchOptions: RequestInit = {
      method: 'POST',
      headers,
      body: JSON.stringify(request),
      signal: combinedSignal.signal,
    }
    
    debugLog(`ğŸ”’ [DEBUG] callLocalModel - Using HTTPS with SSL verification disabled`)
    
    const res = await fetch(url, fetchOptions)
    clearTimeout(timeoutId) // æ¸…é™¤è¶…æ—¶å®šæ—¶å™¨
    
    debugLog(`ğŸ“¥ [DEBUG] callLocalModel - Response status: ${res.status}`)
    debugLog(`ğŸ“¥ [DEBUG] callLocalModel - Response headers:`, JSON.stringify(Object.fromEntries(res.headers.entries()), null, 2))

    // è·å–å“åº”æ–‡æœ¬
    const text = await res.text()
    debugLog(`ğŸ“¥ [DEBUG] callLocalModel - Response text:`, text.substring(0, 500))
    
    if (!res.ok) {
      debugLog(`âŒ [DEBUG] callLocalModel - HTTP error ${res.status}: ${text}`)
      throw new Error(`Local model HTTP error ${res.status}: ${text}`)
    }
    
    // æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©º
    if (!text || text.trim().length === 0) {
      debugLog(`âŒ [DEBUG] callLocalModel - Empty response`)
      throw new Error('Local model returned empty response')
    }
    
    try {
      const parsed = JSON.parse(text) as LocalResponse
      
      // æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«é”™è¯¯ä¿¡æ¯ - å‚è€ƒlocalAdapter.ts
      if (parsed.error) {
        const errorMessage = parsed.error.message || parsed.error.code || 'Unknown error'
        throw new Error(`Local model server error: ${errorMessage}`)
      }
      
      // æ£€æŸ¥æ˜¯å¦æœ‰ choices æ•°ç»„ - å‚è€ƒlocalAdapter.ts
      if (!parsed.choices || !Array.isArray(parsed.choices) || parsed.choices.length === 0) {
        throw new Error('Local model server returned invalid response: missing choices array')
      }
      
      debugLog(`âœ… [DEBUG] callLocalModel - Successfully parsed JSON response`)
      return parsed
      
    } catch (err) {
      debugLog(`âŒ [DEBUG] callLocalModel - JSON parse error:`, err)
      throw new Error(`Failed to parse local model JSON: ${err}`)
    }
  } catch (error) {
    debugLog(`âŒ [DEBUG] callLocalModel - Fetch error:`, error)
    debugLog(`âŒ [DEBUG] callLocalModel - Error type:`, typeof error)
    debugLog(`âŒ [DEBUG] callLocalModel - Error message:`, error instanceof Error ? error.message : String(error))
    debugLog(`âŒ [DEBUG] callLocalModel - Error stack:`, error instanceof Error ? error.stack : 'No stack trace')
    
    // å‚è€ƒlocalAdapter.tsçš„é”™è¯¯å¤„ç†
    if (error instanceof Error) {
      if (error.name === 'AbortError') {
        const timeout = parseInt(process.env.LOCAL_MODEL_TIMEOUT || '30000')
        throw new Error(`Request timeout after ${timeout}ms. Please check your local model server response time or increase LOCAL_MODEL_TIMEOUT.`)
      }
      
      if (error.name === 'TypeError' && error.message.includes('fetch')) {
        throw new Error(`Cannot connect to local model server at ${LOCAL_MODEL_BASE}. Please check if the server is running and the URL is correct.`)
      }
    }
    
    throw error
  }
}

/**
 * æŸ¥è¯¢ local æ¨¡å‹
 */
export async function queryLocalModel(
  messages: (UserMessage | AssistantMessage)[],
  systemPrompt: string[],
  maxThinkingTokens: number, // unused for now
  tools: Tool[],
  signal: AbortSignal,
  options: {
    dangerouslySkipPermissions: boolean
    model: string
    prependCLISysprompt: boolean
  },
): Promise<AssistantMessage> {
  const startTime = Date.now()
  debugLog(`ğŸš€ [DEBUG] queryLocalModel - Starting with model: ${options.model}`)
  debugLog(`ğŸš€ [DEBUG] queryLocalModel - Messages count: ${messages.length}`)
  debugLog(`ğŸš€ [DEBUG] queryLocalModel - System prompt items: ${systemPrompt.length}`)
  debugLog(`ğŸš€ [DEBUG] queryLocalModel - Tools count: ${tools.length}`)
  debugLog(`ğŸš€ [DEBUG] queryLocalModel - LOCAL_MODEL_BASE: ${LOCAL_MODEL_BASE}`)
  debugLog(`ğŸš€ [DEBUG] queryLocalModel - LOCAL_MODEL_API_KEY: ${LOCAL_MODEL_API_KEY ? 'set' : 'not set'}`)
  
  try {
    // Build messages
    const localMessages: LocalMessage[] = []
    if (systemPrompt.length) {
      localMessages.push({ role: 'system', content: systemPrompt.join('\n\n') })
      debugLog(`ğŸ“ [DEBUG] queryLocalModel - Added system prompt`)
    }
    for (const m of messages) {
      if (m.type === 'user') {
        localMessages.push(userMessageToLocal(m))
        debugLog(`ğŸ“ [DEBUG] queryLocalModel - Added user message: ${typeof m.message.content === 'string' ? m.message.content.substring(0, 50) : 'complex content'}`)
      } else {
        localMessages.push(assistantMessageToLocal(m as AssistantMessage))
        debugLog(`ğŸ“ [DEBUG] queryLocalModel - Added assistant message`)
      }
    }

    // è·å–æ¨¡å‹åç§°å¹¶æ£€æµ‹æ¨¡å‹ç±»å‹
    const modelName = options.model;
    const modelType = detectModelType(modelName);
    debugLog(`ğŸ”§ [DEBUG] queryLocalModel - Model name: ${modelName}, detected type: ${modelType}`)

    // æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®max_tokens - å‚è€ƒ localAdapter.ts
    const getMaxTokensForLocalModel = (model: string, modelType: string): number => {
      const lowerModel = model.toLowerCase()
      if (lowerModel.includes('v3')) {
        return 128000  // V3 æ¨¡å‹æ”¯æŒ128K
      }
      if (lowerModel.includes('v2.5')) {
        return 128000  // V2.5 æ¨¡å‹æ”¯æŒ128K
      }
      if (lowerModel.includes('coder')) {
        return 32000   // Coder æ¨¡å‹æ”¯æŒ32K
      }
      if (lowerModel.includes('chat')) {
        return 32000   // Chat æ¨¡å‹æ”¯æŒ32K
      }
      if (modelType === 'deepseek-coder') {
        return 32000   // DeepSeek Coder ç±»å‹
      }
      if (modelType === 'gpt') {
        return 32000   // GPT å…¼å®¹æ¨¡å‹
      }
      return 32000     // é»˜è®¤32K
    }
    
    const maxTokens = getMaxTokensForLocalModel(modelName, modelType)
    debugLog(`ğŸ”§ [DEBUG] queryLocalModel - Model: ${modelName}, type: ${modelType}, max_tokens: ${maxTokens}`)

    // æ„é€ è¯·æ±‚ä½“ - å‚è€ƒ localAdapter.ts çš„ convertToLocalRequest
    const requestObj: any = {
      model: modelName,
      messages: localMessages,
      stream: false,
      temperature: 0,
      max_tokens: 300,  // ä½¿ç”¨ä¸curlç›¸åŒçš„å€¼
      // ç§»é™¤æ‰€æœ‰æœåŠ¡å™¨ä¸æ”¯æŒçš„å­—æ®µ
      // presence_penalty: 0,
      // frequency_penalty: 0,
      // top_p: 1,
    };

    // æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´è¯·æ±‚å‚æ•° - å‚è€ƒ localAdapter.ts
    adjustRequestForModel(requestObj, modelType);
    
    // æ·»åŠ å·¥å…·
    if (tools.length > 0) {
      const limitedTools = tools.slice(0, 2)
      debugLog(`ğŸ”§ [DEBUG] queryLocalModel - Limiting tools from ${tools.length} to ${limitedTools.length}`)
      requestObj.tools = toolsToLocal(limitedTools)
    }

    // æ·»åŠ ç®€åŒ–æ¨¡å¼æµ‹è¯• - åªç§»é™¤toolsä½†ä¿ç•™system prompt
    const simplifiedMode = process.env.LOCAL_MODEL_SIMPLIFIED === 'true'
    if (simplifiedMode) {
      debugLog(`ğŸ”§ [DEBUG] queryLocalModel - Using simplified mode - removing tools but keeping system prompt`)
      
      // ç§»é™¤tools
      if (requestObj.tools && requestObj.tools.length > 0) {
        debugLog(`ğŸ”§ [DEBUG] queryLocalModel - Removing ${requestObj.tools.length} tools`)
        delete requestObj.tools
      }
      
      // ç®€åŒ–system prompt - ä½¿ç”¨éå¸¸ç®€å•çš„promptè¿›è¡Œæµ‹è¯•
      if (requestObj.messages.length > 0 && requestObj.messages[0].role === 'system') {
        const originalSystemPrompt = requestObj.messages[0].content
        const simplifiedSystemPrompt = 'You are a helpful assistant.'
        requestObj.messages[0].content = simplifiedSystemPrompt
        debugLog(`ğŸ”§ [DEBUG] queryLocalModel - Simplified system prompt from ${originalSystemPrompt.length} to ${simplifiedSystemPrompt.length} characters`)
      }
      
      // å®Œå…¨ç§»é™¤system promptè¿›è¡Œæµ‹è¯•
      requestObj.messages = requestObj.messages.filter(msg => msg.role !== 'system')
      debugLog(`ğŸ”§ [DEBUG] queryLocalModel - Removed system prompt, remaining messages: ${requestObj.messages.length}`)
    }

    debugLog(`ğŸ“¤ [DEBUG] queryLocalModel - Built request with ${localMessages.length} messages`)
    debugLog('ğŸŒ [local_model] Request:', JSON.stringify(requestObj).substring(0, 500))

    debugLog(`ğŸŒ [DEBUG] queryLocalModel - Calling callLocalModel...`)
    const response = await callLocalModel(requestObj, signal)
    debugLog(`âœ… [DEBUG] queryLocalModel - callLocalModel completed successfully`)

    const durationMs = Date.now() - startTime
    debugLog(`â±ï¸ [DEBUG] queryLocalModel - Total duration: ${durationMs}ms`)

    const choice = response.choices[0]
    if (!choice) {
      debugLog(`âŒ [DEBUG] queryLocalModel - No choices in response`)
      throw new Error('Local model returned no choices')
    }

    debugLog(`âœ… [DEBUG] queryLocalModel - Response has ${response.choices.length} choices`)
    debugLog(`âœ… [DEBUG] queryLocalModel - Choice content: ${choice.message.content || 'no content'}`)

    const assistantMsg: AssistantMessage = {
      costUSD: 0,
      durationMs,
      type: 'assistant',
      uuid: crypto.randomUUID(),
      message: {
        id: response.id || `local_${Date.now()}`,
        type: 'assistant',
        role: 'assistant',
        content: choice.message.content ? [{ type: 'text', text: choice.message.content }] : [],
        model: options.model,
        stop_reason: choice.finish_reason || 'end_turn',
        stop_sequence: null,
        usage: {
          input_tokens: response.usage?.prompt_tokens || 0,
          output_tokens: response.usage?.completion_tokens || 0,
        },
      },
    }

    debugLog(`âœ… [DEBUG] queryLocalModel - Created assistant message successfully`)
    debugLog(`âœ… [DEBUG] queryLocalModel - Final message content: ${assistantMsg.message.content[0]?.text || 'no content'}`)

    // tool calls
    if (choice.message.tool_calls?.length) {
      debugLog(`ğŸ”§ [DEBUG] queryLocalModel - Processing ${choice.message.tool_calls.length} tool calls`)
      for (const tc of choice.message.tool_calls) {
        assistantMsg.message.content.push({
          type: 'tool_use',
          id: (tc as any).id || crypto.randomUUID(),
          name: tc.function.name,
          input: JSON.parse(tc.function.arguments),
        })
      }
    }

    return assistantMsg
  } catch (error) {
    const durationMs = Date.now() - startTime
    debugLog(`âŒ [DEBUG] queryLocalModel - Error occurred after ${durationMs}ms`)
    debugLog(`âŒ [DEBUG] queryLocalModel - Error:`, error)
    debugLog(`âŒ [DEBUG] queryLocalModel - Error type:`, typeof error)
    debugLog(`âŒ [DEBUG] queryLocalModel - Error message:`, error instanceof Error ? error.message : String(error))
    logError(error)
    return {
      costUSD: 0,
      durationMs,
      type: 'assistant',
      uuid: crypto.randomUUID(),
      isApiErrorMessage: true,
      message: {
        id: `local_error_${Date.now()}`,
        type: 'assistant',
        role: 'assistant',
        content: [
          {
            type: 'text',
            text: `Error calling local model: ${error instanceof Error ? error.message : String(error)}`,
          },
        ],
        model: options.model,
        stop_reason: 'error',
        stop_sequence: null,
        usage: { input_tokens: 0, output_tokens: 0 },
      },
    }
  }
}